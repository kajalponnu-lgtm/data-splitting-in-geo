library(dplyr)
# assume your data.frame is named DEM_variability_points_main90_cleaned
df <- DEM_variability_points_main90_cleaned
getwd("C:/Users/User/Documents/R script/data cleaning")
setwd("C:/Users/User/Documents/R script/data cleaning")
df <- read.csv("DEM_variability_points_main90_cleaned.csv")
setwd("C:/Users/User/Documents/R script/data cleaning")
df <- read.csv("DEM_variability_points_main90_cleaned.csv")
setwd("C:/Users/User/Documents/R script/data cleaning")
# Step 1: set working directory
setwd("C:/Users/User/Documents/R script/data cleaning")
setwd("C:/Users/User/Documents/R script/data splitting in geo")
list.files()
# Step 1: set working directory
setwd("C:/Users/User/Documents/R script/data splitting in geo")
# Step 2: load your CSV
df <- read.csv("DEM_variability_points_main90_cleaned.csv")
# Step 3: check it loaded correctly
head(df)        # see first few rows
colnames(df)    # check column names
library(dplyr)
set.seed(42)
# ---- Step 1: decide number of clusters
k <- round(sqrt(nrow(df) / 2))
# ---- Step 2: run k-means on coordinates
km <- kmeans(scale(df[, c("longitude","latitude")]), centers = k, nstart = 25)
df$cluster <- km$cluster
# ---- Step 3: randomly order clusters and assign ~75% to calibration
clust_sizes <- df %>% count(cluster) %>% sample_frac(1)
clust_sizes <- clust_sizes %>% mutate(cum = cumsum(n)/sum(n))
cal_clusters <- clust_sizes$cluster[clust_sizes$cum <= 0.75]
if (sum(df$cluster %in% cal_clusters)/nrow(df) < 0.75) {
next_cl <- clust_sizes$cluster[which.min(abs(clust_sizes$cum - 0.75))]
cal_clusters <- unique(c(cal_clusters, next_cl))
}
df$set <- ifelse(df$cluster %in% cal_clusters, "calibration", "validation")
# ---- Step 4: check split
table(df$set) / nrow(df)
install.packages("FNN")   # only once
library(FNN)
cal_coords <- df[df$set == "calibration", c("longitude", "latitude")]
val_coords <- df[df$set == "validation", c("longitude", "latitude")]
nn <- get.knnx(cal_coords, val_coords, k = 1)
distances <- nn$nn.dist[,1]   # vector of min distances
summary(distances)  # min, 1st quartile, median, mean, max
hist(distances,
breaks = 30,
main = "Nearest Distances (Validation → Calibration)",
xlab = "Distance (degrees)")
library(FNN)
# Extract coordinates
cal_coords <- df[df$set == "calibration", c("longitude", "latitude")]
val_coords <- df[df$set == "validation", c("longitude", "latitude")]
# Compute nearest calibration neighbor for each validation point
nn <- get.knnx(cal_coords, val_coords, k = 1)
distances <- nn$nn.dist[,1]
# Numeric summary
summary(distances)
# Extra: quantiles at 5%, 10%, 25%, 50%, 75%, 90%, 95%
quantile(distances, probs = c(0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95))
# Mean & SD
mean(distances)
sd(distances)
library(gstat)
library(sp)
# Suppose your dataframe is df with columns: longitude, latitude, and target variable (e.g., Zn)
coordinates(df) <- ~longitude+latitude  # make it spatial
# Compute experimental variogram
vgm_exp <- variogram(target_variable ~ 1, df)   # replace target_variable with your column name
install.packages("gstat")
library(gstat)
library(sp)
# Suppose your dataframe is df with columns: longitude, latitude, and target variable (e.g., Zn)
coordinates(df) <- ~longitude+latitude  # make it spatial
library(gstat)
library(sp)
# Compute experimental variogram
vgm_exp <- variogram(target_variable ~ 1, df)   # replace target_variable with your column name
names(df)
library(gstat)
vgm_exp <- variogram(ph_0_5 ~ 1, df)   # experimental variogram
plot(vgm_exp)
# Convert to data frame
vgm_df <- as.data.frame(vgm_exp)
# View first few rows
head(vgm_df)
# Save to CSV
write.csv(vgm_df, "variogram_output.csv", row.names = FALSE)
install.packages("blockCV")
library(sf)
cutoff <- 0.002
set.seed(123)
# Randomly pick calibration points
calib <- data[sample(1:nrow(data), floor(0.7*nrow(data))), ]
library(sp)   # or sf if your data is in sf format
# Example: data is a SpatialPointsDataFrame
coords <- coordinates(data)
library(sf)
library(dplyr)
# Example cutoff (block size)
cutoff <- 0.002
# Convert df to sf object (if not already)
df_sf <- st_as_sf(df, coords = c("x", "y"), crs = 4326)  # change cols if needed
# Make a grid of blocks
grid <- st_make_grid(df_sf, cellsize = cutoff)
# Assign each point to a block
df_sf$block_id <- st_within(df_sf, grid) %>% as.integer()
# Randomly select 70% of blocks for calibration
set.seed(123)
unique_blocks <- unique(df_sf$block_id)
calib_blocks <- sample(unique_blocks, size = floor(0.7*length(unique_blocks)))
# Split
calib <- df_sf %>% filter(block_id %in% calib_blocks)
valid <- df_sf %>% filter(!block_id %in% calib_blocks)
library(sf)
library(dplyr)
# Example cutoff (block size)
cutoff <- 0.002
# Convert df to sf object (replace "longitude" and "latitude" with your column names)
df_sf <- st_as_sf(df, coords = c("longitude", "latitude"), crs = 4326)
# Make a grid of blocks
grid <- st_make_grid(df_sf, cellsize = cutoff)
# Assign each point to a block
df_sf$block_id <- st_within(df_sf, grid) %>% sapply(as.integer)
# Randomly select 70% of blocks for calibration
set.seed(123)
unique_blocks <- unique(df_sf$block_id)
calib_blocks <- sample(unique_blocks, size = floor(0.7*length(unique_blocks)))
# Split into calibration and validation
calib <- df_sf %>% filter(block_id %in% calib_blocks)
valid <- df_sf %>% filter(!block_id %in% calib_blocks)
# Check how many points in each
table(c(ifelse(df_sf$block_id %in% calib_blocks, "calibration", "validation")))
library(FNN)
# Extract coordinates
cal_coords <- st_coordinates(calib)
val_coords <- st_coordinates(valid)
# Nearest neighbor distances from validation → calibration
nn <- get.knnx(cal_coords, val_coords, k = 1)
distances <- nn$nn.dist[,1]
# Summary
summary(distances)
# Keep only validation points at least cutoff away
valid_filtered <- valid[distances >= 0.002, ]
library(sf)
library(FNN)
library(dplyr)
# --- Step 1: define cutoff distance
cutoff <- 0.002
set.seed(123)
# --- Step 2: convert to sf (if not already)
df_sf <- st_as_sf(df, coords = c("longitude", "latitude"), crs = 4326)
# --- Step 3: shuffle points
df_sf <- df_sf %>% slice_sample(prop = 1)
# --- Step 4: initialize empty sets
calib <- df_sf[0, ]
valid <- df_sf[0, ]
# --- Step 5: loop through points
for (i in 1:nrow(df_sf)) {
pt <- df_sf[i, ]
# if calib empty, put first point there
if (nrow(calib) == 0) {
calib <- rbind(calib, pt)
} else {
# compute distance to all calibration points
dist_to_cal <- get.knnx(st_coordinates(calib), st_coordinates(pt), k = 1)$nn.dist[,1]
if (dist_to_cal >= cutoff) {
valid <- rbind(valid, pt)  # add to validation if far enough
} else {
calib <- rbind(calib, pt)  # otherwise keep in calibration
}
}
}
# --- Step 6: check
cat("Calibration points:", nrow(calib), "\n")
cat("Validation points:", nrow(valid), "\n")
# --- Step 7: verify distances
nn <- get.knnx(st_coordinates(calib), st_coordinates(valid), k = 1)
summary(nn$nn.dist[,1])   # min distance should now >= cutoff
cutoff <- 0.005   # increase for more separation
set.seed(123)
calib <- df_sf[0, ]
valid <- df_sf[0, ]
for (i in 1:nrow(df_sf)) {
pt <- df_sf[i, ]
if (nrow(calib) == 0) {
calib <- rbind(calib, pt)
} else {
# distance to all calibration points
dist_to_cal <- get.knnx(st_coordinates(calib), st_coordinates(pt), k = nrow(calib))$nn.dist[,1]
if (all(dist_to_cal >= cutoff)) {
valid <- rbind(valid, pt)
} else {
calib <- rbind(calib, pt)
}
}
}
# Verify
cat("Calibration points:", nrow(calib), "\n")
cat("Validation points:", nrow(valid), "\n")
nn <- get.knnx(st_coordinates(calib), st_coordinates(valid), k = 1)
summary(nn$nn.dist[,1])
cutoff <- 0.005   # increase for more separation
set.seed(123)
calib <- df_sf[0, ]
valid <- df_sf[0, ]
for (i in 1:nrow(df_sf)) {
pt <- df_sf[i, ]
if (nrow(calib) == 0) {
calib <- rbind(calib, pt)
} else {
# distance to all calibration points
dist_to_cal <- get.knnx(st_coordinates(calib), st_coordinates(pt), k = nrow(calib))$nn.dist[,1]
if (all(dist_to_cal >= cutoff)) {
valid <- rbind(valid, pt)
} else {
calib <- rbind(calib, pt)
}
}
}
# Verify
cat("Calibration points:", nrow(calib), "\n")
cat("Validation points:", nrow(valid), "\n")
nn <- get.knnx(st_coordinates(calib), st_coordinates(valid), k = 1)
summary(nn$nn.dist[,1])
library(sf)
library(FNN)
library(dplyr)
set.seed(123)
# Convert to sf if not already
df_sf <- st_as_sf(df, coords = c("longitude", "latitude"), crs = 4326)
# Shuffle points
df_sf <- df_sf %>% slice_sample(prop = 1)
# Initialize
calib <- df_sf[0, ]
valid <- df_sf[0, ]
# Start with small cutoff and increase if needed
cutoff <- 0.002
for (i in 1:nrow(df_sf)) {
pt <- df_sf[i, ]
if (nrow(calib) == 0) {
calib <- rbind(calib, pt)
} else {
# compute distances to all calibration points
dist_to_cal <- get.knnx(st_coordinates(calib), st_coordinates(pt), k = nrow(calib))$nn.dist[,1]
if (all(dist_to_cal >= cutoff)) {
valid <- rbind(valid, pt)
} else {
calib <- rbind(calib, pt)
}
}
}
# If validation too small, lower cutoff slightly
while (nrow(valid) < 0.25 * nrow(df_sf)) {
cutoff <- cutoff * 0.9  # reduce by 10%
# Reset sets
calib <- df_sf[0, ]
valid <- df_sf[0, ]
for (i in 1:nrow(df_sf)) {
pt <- df_sf[i, ]
if (nrow(calib) == 0) {
calib <- rbind(calib, pt)
} else {
dist_to_cal <- get.knnx(st_coordinates(calib), st_coordinates(pt), k = nrow(calib))$nn.dist[,1]
if (all(dist_to_cal >= cutoff)) {
valid <- rbind(valid, pt)
} else {
calib <- rbind(calib, pt)
}
}
}
}
# Verify split
cat("Calibration points:", nrow(calib), "\n")
cat("Validation points:", nrow(valid), "\n")
# Verify distances
nn <- get.knnx(st_coordinates(calib), st_coordinates(valid), k = 1)
summary(nn$nn.dist[,1])
library(sf)
library(FNN)
library(dplyr)
set.seed(123)
# --- Step 1: define cutoff distance
cutoff <- 0.002
# --- Step 2: convert to sf
df_sf <- st_as_sf(df, coords = c("longitude", "latitude"), crs = 4326)
# --- Step 3: randomly assign 70% of points to calibration
calib_indices <- sample(1:nrow(df_sf), size = floor(0.7 * nrow(df_sf)))
calib <- df_sf[calib_indices, ]
# --- Step 4: remaining points are candidates for validation
remaining <- df_sf[-calib_indices, ]
# --- Step 5: filter remaining points by distance from calibration
valid <- remaining[0, ]
for (i in 1:nrow(remaining)) {
pt <- remaining[i, ]
dist_to_cal <- get.knnx(st_coordinates(calib), st_coordinates(pt), k = nrow(calib))$nn.dist[,1]
if (all(dist_to_cal >= cutoff)) {
valid <- rbind(valid, pt)
}
}
# --- Step 6: final check
cat("Calibration points:", nrow(calib), "\n")
cat("Validation points:", nrow(valid), "\n")
# --- Step 7: check nearest distances
nn <- get.knnx(st_coordinates(calib), st_coordinates(valid), k = 1)
summary(nn$nn.dist[,1])
library(sf)
library(FNN)
library(dplyr)
set.seed(123)
# Convert to sf if not already
df_sf <- st_as_sf(df, coords = c("longitude", "latitude"), crs = 4326)
# Shuffle points
df_sf <- df_sf %>% slice_sample(prop = 1)
# Desired proportion
calib_prop <- 0.7
target_calib <- floor(calib_prop * nrow(df_sf))
# Initialize
cutoff <- 0.002   # starting cutoff
step <- 0.0002    # how much to reduce if validation too small
repeat {
# Step 1: randomly assign calibration points
calib_indices <- sample(1:nrow(df_sf), size = target_calib)
calib <- df_sf[calib_indices, ]
# Step 2: remaining points
remaining <- df_sf[-calib_indices, ]
# Step 3: assign validation points if far enough from all calib points
valid <- remaining[0, ]
for (i in 1:nrow(remaining)) {
pt <- remaining[i, ]
dist_to_cal <- get.knnx(st_coordinates(calib), st_coordinates(pt), k = nrow(calib))$nn.dist[,1]
if (all(dist_to_cal >= cutoff)) {
valid <- rbind(valid, pt)
}
}
# Step 4: check proportion of validation
if (nrow(valid) >= 0.25 * nrow(df_sf)) break
cutoff <- cutoff - step   # reduce cutoff slightly
if (cutoff <= 0) break    # prevent negative cutoff
}
# Final check
cat("Calibration points:", nrow(calib), "\n")
cat("Validation points:", nrow(valid), "\n")
# Verify nearest distances
nn <- get.knnx(st_coordinates(calib), st_coordinates(valid), k = 1)
summary(nn$nn.dist[,1])
# Convert sf objects back to regular data.frames (if needed)
calib_df <- as.data.frame(calib)
valid_df <- as.data.frame(valid)
# Save to CSV
write.csv(calib_df, "calibration_points.csv", row.names = FALSE)
write.csv(valid_df, "validation_points.csv", row.names = FALSE)
